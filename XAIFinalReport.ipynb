{
 "cells": [
  {
   "cell_type": "raw",
   "id": "a31c8d75",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "title: \"Final Report\"\n",
    "subtitle: \"Interactive and Explainable AI\"\n",
    "author:\n",
    "  - name: \"Stijn But\"\n",
    "  - name: \"Minji Kim\"\n",
    "  - name: \"Xuechun Lyu\"\n",
    "  - name: \"Sercan Şeref\"\n",
    "date: \"28 May 2025\"\n",
    "bibliography: lib.bib\n",
    "abstract: |\n",
    "  This report presents the design, development, and evaluation of an interactive explainable AI (XAI) dashboard aimed at helping data science students—particularly first-time home buyers—interpret housing price predictions. Addressing the \"disagreement problem\" in XAI, the dashboard enables users to compare multiple explanation methods (SHAP, LIME, Integrated Gradients, SmoothGrad, and GradientShap) side-by-side, fostering transparency and trust in model outputs. The project combines user research, creative ideation, and iterative prototyping to deliver a tool that balances technical rigor with usability. Qualitative user testing highlights the dashboard’s effectiveness in clarifying feature importance and model behavior, while also identifying areas for further improvement in interpretability and user experience. The findings contribute practical insights for designing accessible XAI tools in real-world decision-making contexts.\n",
    "lang: \"en\"\n",
    "jupyter: python3 \n",
    "format:\n",
    "  pdf: \n",
    "    number-sections: true\n",
    "    colorlinks: true\n",
    "    documentclass: scrartcl\n",
    "    papersize: letter\n",
    "    toc: true\n",
    "code-line-numbers: true\n",
    "execute:\n",
    "  enabled: true\n",
    "  warning: true\n",
    "  error: true\n",
    "---\n",
    "\n",
    "\\newpage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c66786d",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# Introduction\n",
    "\n",
    "The disagreement problem, as highlighted by Kaur, emphasizes the challenge of interpreting conflicting feature importances provided by different explanation tools and methods. [@kaur2020] This issue is particularly relevant in the context of dashboarding and explanation tools, where users often struggle with varying explanation styles and visualizations. The lack of a standardized approach to feature importance can lead to confusion and misinterpretation, especially for users who may not have a deep understanding of the underlying data science concepts.\n",
    "\n",
    "Our project addresses this challenge by designing a dashboard specifically tailored for data science students. The dashboard aims to help users understand the features that contribute to housing price predictions by enabling them to compare multiple explanation methods side-by-side. This comparison provides insights into how different methods attribute importance and supports users in interpreting these explanations more effectively.\n",
    "\n",
    "The relevance of such a tool is particularly strong when considering the Dutch housing market, where housing prices have risen sharply in recent years. According to CBS, the prices of existing homes are now higher than during the previous peak in 2008, with the pace of price increases slowing slightly around 2019 before accelerating again. [@cbs2024dashboard] In a market where finding affordable housing is increasingly challenging, a tool that explains housing price predictions in an accessible and transparent way can help users better understand the factors driving property prices and support more informed decision-making.\n",
    "\n",
    "We chose to focus on first-time house buyers, as they often face difficulties in understanding which features contribute most to a home's value. Given that first-time buyers are usually early in their careers and lack prior investment experience, they stand to benefit greatly from clear and interpretable AI explanations. Targeting data science students within this group was a deliberate choice, as their foundational knowledge of data concepts allows them to engage with and benefit from the explanations provided by the dashboard more effectively.\n",
    "\n",
    "- *Design debrief*\n",
    "\n",
    "To achieve this, we conducted user research and pilot testing using standard dashboarding tools. Based on the findings, we designed a prototype dashboard that aligns with the needs of our target audience. The datasets used for this project are sourced from the course materials or other relevant projects.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2822528f",
   "metadata": {},
   "source": [
    "# Empathize\n",
    "\n",
    "## Explanation Methods in Machine Learning\n",
    "\n",
    "We utilized various explanation methods introduced during the initial lectures and explored through the notebooks provided by the lecturers, including SHAP, LIME, Integrated Gradients, SmoothGrad, and GradientShap. These notebooks not only helped us understand the theoretical aspects of these methods but also demonstrated their practical applicability, showing that we could effectively use these techniques to address the housing problem in the Netherlands. Each of these methods offers unique approaches to understanding feature importance and model interpretability.\n",
    "\n",
    "The emergence of Explainable Artificial Intelligence (XAI) represents a critical development in addressing the opacity of complex machine learning models. Traditional predictive models, particularly those employed in high-stakes domains such as finance, healthcare, and housing economics, often suffer from a lack of interpretability. To bridge this gap, a variety of explanation techniques have been proposed, each offering different perspectives on how input features contribute to model outputs.\n",
    "\n",
    "Local Interpretable Model-Agnostic Explanations (LIME), introduced by Ribeiro et al. (2016), is a seminal contribution in this regard. LIME operates by approximating a complex model locally around a prediction using a simpler, interpretable surrogate model, often a linear regression. Through perturbing input data and observing output variations, LIME offers intuitive explanations that are particularly useful in understanding the behavior of highly non-linear models.\n",
    "\n",
    "Another important advancement is SHapley Additive exPlanations (SHAP), formulated by Lundberg and Lee (2017). Rooted in cooperative game theory, SHAP assigns each feature an importance value for a particular prediction by considering the contribution of features across all possible combinations. SHAP stands out due to its axiomatic foundation, guaranteeing properties such as local accuracy, consistency, and missingness, which are crucial for ensuring credible model interpretations.\n",
    "\n",
    "Integrated Gradients, proposed by Sundararajan et al. (2017), takes a different approach, specifically designed for interpreting deep neural networks. This method attributes the change in prediction between a baseline and the actual input by integrating the gradients along a linear path. It satisfies important theoretical properties, such as sensitivity and implementation invariance, making it particularly suited for continuous and complex input spaces like images or tabular financial data.\n",
    "\n",
    "Another notable method is SmoothGrad, introduced by Smilkov et al. (2017), which improves the clarity of saliency maps by adding noise to the inputs and averaging the resulting gradients. Although initially proposed for visual data, adaptations of SmoothGrad to tabular data offer enhanced feature visualization by reducing noise and highlighting the regions of true importance.\n",
    "\n",
    "Overall, these explanation methods each bring unique strengths. LIME offers model-agnostic, localized explanations ideal for exploratory analysis; SHAP provides a globally consistent, theoretically sound framework; Integrated Gradients excel in deep learning contexts; and SmoothGrad enhances the robustness and visual clarity of explanations. The synergy of these techniques creates a comprehensive interpretability toolkit essential for advancing transparent and trustworthy machine learning applications in various domains, including the housing market.\n",
    "\n",
    "## Applications of Explanation Methods to Housing Market Analysis\n",
    "\n",
    "The housing market has historically been analyzed through hedonic pricing models, wherein property characteristics such as location, size, and amenities are linked to price. However, with the advent of machine learning, more sophisticated models like Random Forests, XGBoost, and deep neural networks have demonstrated superior predictive capabilities. These advancements, while improving accuracy, have exacerbated concerns about model transparency, particularly in socially and economically sensitive sectors such as real estate.\n",
    "\n",
    "The application of XAI methods to housing market analysis addresses this issue by elucidating the underlying drivers of model predictions. For instance, Özçelik and Yildirim (2022) conducted a comparative study applying SHAP and LIME to real estate valuation models. Their findings consistently demonstrated that variables such as location proximity to urban centers, size of the dwelling, quality of neighborhood amenities, and macroeconomic indicators such as interest rates are the dominant predictors of property prices. Importantly, SHAP and LIME provided granular, instance-specific insights that enabled a deeper understanding of the multifaceted factors influencing real estate valuation.\n",
    "\n",
    "Feature importance analyses using SHAP and LIME have revealed recurrent patterns across various studies. Location factors, such as distance to city centers and accessibility to public transport, emerge as primary determinants of housing prices. Demographic variables, including median income levels and employment rates, also exhibit significant influence. Moreover, market dynamics such as housing supply-demand ratios and mortgage interest rates are critical economic indicators that affect property values. Physical attributes of houses, including size, number of rooms, age, and the presence of amenities such as gardens or parking spaces, consistently appear among the top predictors across diverse datasets.\n",
    "\n",
    "A particularly novel contribution to this field is the work by De Nadai et al. (2016), who utilized mobile phone activity data to quantify urban vitality, subsequently demonstrating its predictive power for housing price fluctuations. This study highlighted the potential of integrating unconventional datasets and features into traditional housing models, further underscoring the versatility of XAI methods in uncovering hidden patterns. \n",
    "\n",
    "Focusing specifically on the Dutch housing market, reports by Statistics Netherlands (CBS) and research conducted by Rabobank indicate distinct patterns that are critical for modeling efforts. Urbanization has driven significant price increases within the Randstad metropolitan region compared to rural provinces. [@cbs2024housing] Fluctuations in mortgage interest rates have shown a strong correlation with transaction volumes, emphasizing the sensitivity of the housing market to macroeconomic policy changes. Additionally, government interventions such as rent control policies and adjustments in mortgage lending standards have significantly influenced market dynamics. [@rabobank2024]\n",
    "\n",
    "In constructing educational dashboards aimed at data science students, the integration of explanation methods is particularly advantageous. Visual tools such as SHAP summary plots and LIME explanation graphs allow users to intuitively grasp the complex interplay of features driving housing market predictions. Furthermore, scenario simulation functionalities, wherein users can modify input features and observe corresponding changes in predictions, offer a hands-on understanding of model behavior. According to Molnar (2020), effective communication of explanations requires careful consideration of the audience’s domain knowledge, making simplicity, visual clarity, and contextual relevance crucial design principles.\n",
    "\n",
    "In conclusion, the integration of explanation methods into housing market analysis not only enhances model transparency but also facilitates a deeper comprehension of the economic, demographic, and physical factors shaping real estate dynamics. This synergy between advanced predictive modeling and interpretability is particularly valuable in educational contexts, equipping data science students with the necessary skills to build, critique, and trust predictive systems deployed in real-world scenarios.\n",
    "\n",
    "## User Research and Pilot Testing\n",
    "\n",
    "To gain a deep and empathetic understanding of the problem space and our potential users, we conducted exploratory user research centered around a prototype dashboard for explainable AI in the housing domain. Although the dashboard was not yet fully deployed in a real-world setting, participants engaged with interactive mockups and guided walkthroughs that closely simulated the intended user experience. This approach enabled us to evaluate early design concepts and explanation strategies using qualitative methods, including pilot testing, semi-structured interviews, and observational feedback.\n",
    "\n",
    "Our target users were selected for their foundational knowledge of AI and predictive modeling, making them well-suited to critically assess the interpretability and usability of a broad range of XAI methods. This group was intentionally chosen over a broader young adult audience because, while young people in general are a key demographic for first-time home buying, their typically limited experience with data science would have required the dashboard to be extremely simplistic. Achieving such simplicity is particularly challenging with advanced explanation tools such as SHAP, LIME, Integrated Gradients, SmoothGrad, and GradientShap, all of which inherently involve complex visualizations and concepts.\n",
    "\n",
    "By focusing on data science students, we could design a dashboard that leverages users’ existing familiarity with data-driven reasoning, allowing for more nuanced explanations and richer interactions across multiple explanation techniques without overwhelming the audience. Each participant took part in a semi-structured session, guided by a structured feedback matrix (covering Likes, Criticisms, Questions, and Ideas). During these sessions, participants explored how the dashboard visualized housing price predictions using a variety of explanation methods—including global (e.g., SHAP) and local (e.g., LIME) model-agnostic techniques, as well as gradient-based approaches (Integrated Gradients, SmoothGrad, GradientShap) for neural networks. This format encouraged participants to reflect on the clarity, usefulness, and trustworthiness of the outputs, share their preferences, and articulate any difficulties or suggestions for improvement.\n",
    "\n",
    "Several recurring insights emerged from this process. Visual clarity and intuitive color schemes were repeatedly highlighted as essential, with SHAP and gradient-based methods often praised for their structured visuals and consistent layout. In contrast, some explanation outputs—especially those from LIME and certain neural network methods—were perceived as fragmented or more difficult to interpret without additional guidance. The inclusion of a side-by-side explanation comparison was particularly valued, as it made disagreements between methods transparent and encouraged critical reflection on model behavior.\n",
    "\n",
    "However, the exploratory nature of the dashboard also revealed certain limitations. Some users expressed confusion over changing feature importances between samples and across explanation methods, raising concerns about the consistency and reliability of explanations. Others found abstract indexing and the absence of domain-specific context (such as geographic information or real housing listings) to be barriers to understanding. These findings underscored the importance of contextualization and the need for onboarding materials, even in early-stage XAI tools.\n",
    "\n",
    "Despite being a conceptual prototype, the dashboard functioned as a research probe, surfacing how users think about trust, explanation alignment, and AI transparency across a variety of XAI techniques. The pilot testing confirmed that even at an early stage, well-designed visualizations and interactive comparisons can elicit valuable user reactions, inform future design decisions, and align with real user needs. Ultimately, these insights grounded our assumptions in authentic user experience and highlighted key priorities for future development and deployment in fully functional, real-world systems.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b96a848",
   "metadata": {},
   "source": [
    "# Define\n",
    "\n",
    "Leading into the ideation phase, we consolidated insights from both our technical exploration of explainability techniques and the qualitative feedback gathered during early user engagement. This synthesis helped us clearly articulate the problem space and select the most appropriate XAI methods for supporting interpretability in the context of housing price prediction.\n",
    "\n",
    "Through our interviews and pilot testing with data science students, two primary user needs emerged. First, users expressed a desire to understand the role of input features at both a general and individual level. They wanted to grasp how features influence predictions across the entire dataset—such as the general importance of property size or location—as well as understand how those same features contribute to specific predictions for individual houses. Second, many users struggled when faced with conflicting explanations from different XAI methods. This issue, closely aligned with what Kaur et al. (2020) describe as the “disagreement problem,” led to uncertainty and reduced trust in the model’s outputs. Users clearly needed support in interpreting and reconciling these differing perspectives.\n",
    "\n",
    "Our initial scope included a broad range of explanation methods: SHAP, LIME, Integrated Gradients, SmoothGrad, and GradientShap. This selection was motivated by course material, literature, and the technical affordances of each method. However, early user testing revealed key limitations. Gradient-based methods, while theoretically compelling and powerful in neural network contexts, produced explanations that were difficult to interpret within our Streamlit-based interface. The visual outputs of techniques like Integrated Gradients and SmoothGrad—typically saliency maps or noisy bar charts—proved less accessible for users unfamiliar with deep learning or advanced visualization formats.\n",
    "\n",
    "In contrast, SHAP and LIME consistently resonated with users. SHAP’s strength lies in its ability to provide both global and local explanations with a solid theoretical foundation rooted in Shapley values. Users responded positively to the visual clarity of SHAP’s waterfall and summary plots, particularly when these linked feature contributions to monetary impacts, making it highly relevant in the housing domain. LIME offered a complementary perspective. While it required a greater cognitive effort to interpret, its case-specific surrogate models enabled users to explore how slight changes in inputs could lead to different predictions—adding depth to the interpretability experience.\n",
    "\n",
    "Focusing our prototype on SHAP and LIME allowed us to reduce unnecessary complexity, streamline the interface, and ensure that explanation outputs remained accessible to data science students. It also enabled more meaningful side-by-side comparisons, which directly addressed users’ confusion around explanation inconsistency. In short, this narrowing of scope not only improved usability but sharpened the pedagogical value of the dashboard.\n",
    "\n",
    "This led us to a well-defined design challenge: how might we help data science students critically compare and interpret different explanation methods for housing price predictions—especially when those methods disagree? With this framing in mind, the ideation phase focused not just on creating an explainability dashboard, but on designing a comparative explanation interface. The goal was to promote reflective use, guide interpretation, and foster trust in machine learning models by highlighting divergence, offering contextual support, and encouraging informed judgment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "065b35c9",
   "metadata": {},
   "source": [
    "# Ideation\n",
    "\n",
    "## Description of the creative techniques used for divergence and convergence\n",
    "\n",
    "The ideation phase began after we had developed a clear understanding of both the technical landscape of explainable AI (XAI) methods and the cognitive and emotional needs of our target audience: data science students interested in understanding housing price predictions. At this point, our task was not to solve the problem immediately, but to explore its full creative potential through structured divergence and convergence.\n",
    "\n",
    "We initiated the divergence process with a brainstorming session framed by the question: *“How can we make explanation method results easier to understand for people?”* This was designed to be as inclusive and expansive as possible, welcoming both practical and speculative ideas. To support creativity and collaboration, we applied the “Yes, and…” technique. This ensured that no idea was dismissed too early and that suggestions could grow organically through group interaction.\n",
    "\n",
    "The outcomes of this phase reflected a wide range of thinking. Some ideas focused on clarity and visual communication—for example, using red and green color coding to indicate negative and positive feature impacts. Others emphasized personalization and engagement, such as offering simplified or advanced visualizations based on the user’s experience level. Some were clearly ambitious, such as an AI-powered estate agent capable of responding in natural language, or a “What if?” simulator allowing users to tweak house features and view resulting price predictions. While not all of these ideas would be implemented, their diversity reflected a strong understanding of both user needs and the explanatory potential of different XAI techniques.\n",
    "\n",
    "After this expansive creative exploration, we began the convergence phase. Here, we applied the COCD Box method—a structured decision-making tool that categorizes ideas by their feasibility and innovativeness. Each idea was placed into one of four zones: Blue (feasible and easy to implement), Red (innovative and easy to implement), Yellow (innovative but harder to implement), and Grey (expensive or complex to implement). This helped the team identify which ideas could be prioritized for prototyping and which needed to be discarded or saved for future development.\n",
    "\n",
    "Ideas such as using SHAP and LIME together, adding clear labels, using intuitive visual encodings (like SHAP waterfall plots), and including a feature comparison table landed in the Blue Zone. These were feasible, technically grounded, and aligned directly with user needs. In the Red Zone, we placed enhancements like emojis and animations that would humanize the dashboard without overwhelming users. While the Yellow and Grey Zones held intriguing concepts—such as integrating gradient-based methods for neural networks or implementing an AI estate agent—we ultimately set them aside due to limitations in the Streamlit framework and interpretability concerns during pilot testing.\n",
    "\n",
    "This creative process—from wild exploration to structured selection—ensured that we didn’t prematurely settle on an idea and that the final solution reflected both innovation and usability, grounded in direct user feedback and technical viability.\n",
    "\n",
    "## Description of the chosen solution\n",
    "\n",
    "The chosen solution that emerged from our ideation phase is a comparative explanation dashboard designed specifically for data science students seeking to understand housing price predictions. The core aim of this solution is to resolve the \"disagreement problem\" described in Kaur et al. (2020) by enabling users to interpret and critically compare the outputs of two widely used explanation methods: SHAP and LIME. These methods were selected not only for their technical relevance, but also for their complementary strengths in supporting both global and local interpretability.\n",
    "\n",
    "Rather than overwhelming users with a wide array of explanation methods, the dashboard deliberately focuses on SHAP and LIME to keep the interface intuitive while supporting meaningful comparison. SHAP, which is based on Shapley values, offers strong theoretical grounding and was chosen for its dual capability to provide both global explanations (via summary plots) and local explanations (via waterfall plots). Feedback from early prototyping confirmed its usability and appeal, especially when the feature attributions were expressed in monetary terms. LIME was chosen to complement SHAP’s global focus by offering localized surrogate model explanations that show how small changes in input affect individual predictions.\n",
    "\n",
    "While the initial scope included gradient-based methods such as Integrated Gradients and SmoothGrad, these were excluded from the final interface due to performance limitations and interpretability challenges. Users found their visual outputs less accessible, especially when rendered through Streamlit’s limited plotting options. This decision reflected our design principle of prioritizing clarity over complexity.\n",
    "\n",
    "The solution was thus refined into a side-by-side explanation interface that allows users to select a housing sample, view SHAP and LIME explanations for the same prediction, and compare the top features identified by each method. This comparison is supported by an overlap analysis, prompting users to reflect on where explanations agree or diverge. These design decisions were made to promote transparency, reduce cognitive load, and foster interpretability and trust in machine learning predictions—especially in the high-stakes context of housing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f30af5",
   "metadata": {},
   "source": [
    "# Prototype\n",
    "\n",
    "To test our dashboard using Streamlit. This dashboard enables users to explore and compare the explanations generated by two powerful regression models—a tree-based XGBoost Regressor and a Neural Network—trained on a real-world housing price dataset. By integrating multiple state-of-the-art explanation techniques, the dashboard provides users with diverse and complementary insights into model decisions, fostering a clearer understanding of how predictions are formed.\n",
    "\n",
    "![Protoype Dashboard Overview](Images/Protoype1.png)\n",
    "\n",
    "Users begin their interaction by selecting the regression model they want to examine through a sidebar interface. Both models are trained on authentic housing data, and predictions are made on real test samples, ensuring that the explanations are grounded in practical, meaningful scenarios. Users can then select any test instance to analyze in detail, allowing them to investigate predictions on individual, realistic data points.\n",
    "\n",
    "The dashboard incorporates three key explanation methods. SHAP (SHapley Additive exPlanations) offers both local and global perspectives: a local waterfall plot reveals the feature contributions for the chosen sample, while a global summary plot illustrates overall feature importance across the test set. LIME (Local Interpretable Model-agnostic Explanations) complements SHAP by generating interactive, HTML-based local explanations that approximate the model’s behavior near the selected sample. For the Neural Network model, additional gradient-based methods—Integrated Gradients, SmoothGrad, and GradientSHAP—provide further interpretability by highlighting relevant features using advanced backpropagation techniques.\n",
    "\n",
    "![Prototype ](Images/Protoype2.png)\n",
    "\n",
    "To enhance interpretability, the dashboard highlights the top five features identified by SHAP and LIME for the selected instance, and explicitly shows the overlap between these sets. This comparison helps users evaluate the consistency between different explanation methods and builds trust in the model outputs.\n",
    "\n",
    "The user interface is designed to be intuitive and informative. Side-by-side visualizations display SHAP, LIME, and gradient-based explanation plots, enabling users to easily compare the strengths and nuances of each method. The sidebar also includes a feedback form where users can indicate which model and explanation they find most trustworthy and understandable, along with a space for open comments. This feature encourages engagement and provides insights into user preferences and comprehension, though in this final prototype phase it primarily serves as a record of user impressions rather than a mechanism for iterative development.\n",
    "\n",
    "Overall, this prototype serves as a functional test environment aimed at learning from user interaction. It captures the essential steps of the user journey—model selection, explanation inspection, and trust feedback—and is designed to explore how different explanation techniques are received by users in realistic scenarios. By observing these interactions, we can better understand how to refine the dashboard to align more closely with user expectations and support effective decision-making in future versions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de24b53",
   "metadata": {},
   "source": [
    "# Test\n",
    "\n",
    "## Qualitative User Research Methods\n",
    "\n",
    "To evaluate the effectiveness of our dashboard in addressing the disagreement problem and supporting interpretability, we conducted qualitative user research with our target audience: master’s students in data science, AI, and computer science. Our evaluation strategy combined structured user testing with semi-structured feedback collection. This approach ensured we could assess both usability and conceptual clarity from multiple perspectives.\n",
    "\n",
    "Each user participated in a guided test session, during which they freely interacted with the dashboard. Tasks included selecting housing samples, exploring SHAP and LIME explanations, and interpreting the comparative feature analysis. We provided minimal guidance during the session to observe natural engagement and confusion points. These sessions were supplemented by a structured feedback table that captured method preference, visual design opinions, criticisms, questions, and improvement suggestions.\n",
    "\n",
    "## Research Question\n",
    "\n",
    "The central research question guiding our user testing was:  \n",
    "\n",
    "- **\"How do data science students perceive and interpret the explanations provided by different XAI methods in the dashboard, and what are their preferences, challenges, and suggestions for improving the interpretability and usability of housing price prediction models?\"**\n",
    "\n",
    "This question aimed to investigate whether the prototype could effectively support users in understanding the behavior of complex models and resolving discrepancies between different explanation outputs.\n",
    "\n",
    "## Results of the Data Analysis\n",
    "\n",
    "Analysis of user responses revealed several important trends. First, SHAP was the overwhelmingly preferred explanation method, praised for its clarity, intuitive visuals, and direct representation of feature influence (e.g., monetary values). Users described SHAP as easier to interpret and more informative, especially when comparing feature contributions.\n",
    "\n",
    "In contrast, LIME received mixed feedback. While some users found value in its localized explanations, others struggled with redundant or unclear visualizations. Comments frequently mentioned \"too many graphs,\" unclear terminology (such as \"sample index\"), and cognitive overload. There was a clear demand for better onboarding, including a brief user guide, tooltips, or an introductory tutorial explaining how each explanation method works and how to interpret the outputs.\n",
    "\n",
    "A recurring issue was confusion over the lack of overlap between explanation methods. Users often questioned which method to trust when SHAP, LIME, and gradient-based explanations disagreed. This confirmed the relevance of the disagreement problem (Kaur et al., 2020) and underscored the need for improved explanation harmonization or contextual guidance.\n",
    "\n",
    "Several usability issues were also identified. Participants noted slow dashboard performance, especially when switching between complex models like neural networks. Others found the layout of some visualizations (particularly LIME) overwhelming, and recommended simplifying visual elements or providing clearer sectioning. Suggestions included replacing generic index labels with more meaningful identifiers (e.g., “house #12”), adding personalization, and improving visual design polish.\n",
    "\n",
    "An additional challenge emerged from the dashboard’s dual-model structure: both the XGBoost and Neural Network tabs provided SHAP and LIME explanations, while the Neural Network tab also included gradient-based methods—Integrated Gradients, SmoothGrad (via NoiseTunnel + IG), and GradientSHAP. Users frequently struggled to interpret the differences between SHAP and LIME explanations across the two model tabs, and found it difficult to understand how the neural network-specific methods related to the more familiar XGBoost explanations. During user testing, it was also challenging for the team to concisely explain these distinctions, which sometimes led to confusion and reduced confidence in the outputs.\n",
    "\n",
    "From this research, we derived the following key insights for improvement: users need a concise introduction or guide to help them navigate the dashboard and understand explanation methods; visual clutter, especially in LIME sections, should be reduced, with more intuitive labels and polished layouts; replacing index numbers with meaningful names (such as “House A” or “House in Amsterdam”) would improve comprehension; and faster model switching and reduced load times would enhance the fluidity of user interaction. Additionally, clearer communication about the differences between model types and their associated explanation methods is needed to help users make sense of the outputs.\n",
    "\n",
    "In summary, the user research provided valuable insights into how moderately technical users engage with XAI tools and what barriers exist in understanding model behavior. The results confirmed the dashboard’s overall value, especially in enabling comparison and transparency, but also revealed critical usability and communication gaps. These insights are now guiding further iterations—focusing on simplifying LIME outputs, integrating layered explanations, clarifying model and method differences, and improving interaction design to enhance overall clarity and trust in AI predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fba6f6e1",
   "metadata": {},
   "source": [
    "# Conclusion and Recommedations\n",
    "\n",
    "## Conclusion of the User Testing\n",
    "\n",
    "The user testing phase validated the core concept of the dashboard and confirmed its utility in addressing the \"disagreement problem\" in explainable AI. By enabling side-by-side comparisons of SHAP and LIME outputs, the dashboard made explanation differences transparent and promoted user reflection on model reasoning. Our participants found the interface intuitive and informative, especially in understanding which features influenced housing price predictions.\n",
    "\n",
    "SHAP was widely favored for its structured and visually intuitive representation of feature contributions. The inclusion of monetary values helped contextualize the predictions, making them easier to interpret. LIME was appreciated for its case-specific explanations but drew criticism for being more difficult to interpret, especially due to visual clutter and less intuitive output. Despite these challenges, users valued having both methods present, as this encouraged critical comparison and deeper engagement with model behavior.\n",
    "\n",
    "Several constructive suggestions emerged from testing. Users requested better onboarding, including concise tooltips or an introductory guide—particularly to support interpretation of LIME. Others recommended improving sample labeling by replacing abstract index numbers. A few participants also noted that switching between models could cause noticeable performance lags.\n",
    "\n",
    "Useres also found it difficult to compare explanations across tabs. Because toggling between the XGBoost and neural network tabs required waiting for the dashboard to reload, users could not easily keep previous outputs in mind. This made it nearly impossible to spot differences between the explanations provided by each model, further complicating interpretation and reducing the effectiveness of side-by-side comparison.\n",
    "\n",
    "These insights informed several important changes in the prototype. First, we removed the neural network tab entirely. Although it featured additional explanation methods (e.g., GradientSHAP, SmoothGrad via NoiseTunnel, and Integrated Gradients), their outputs were difficult to interpret due to Streamlit’s limited native support for more advanced visualizations. The neural network section also introduced new complexity, sparking additional user questions about how its outputs differed from those of models like XGBoost. In light of the limited clarity and increased cognitive load, removing this tab helped streamline the overall user experience.\n",
    "\n",
    "Additionally, we revised several tooltips to improve clarity and approachability, aligning them better with the data science students' level of familiarity. We also refined interface terminology—for instance, updating labels like “Select a random index” to more understandable phrases like “Select a random house.” This change improved user orientation and made the dashboard feel more aligned with its real-world use case.\n",
    "\n",
    "One of the most impactful improvements was the addition of a toggle that allows users to view the original value of each feature. This feature helps place SHAP and LIME outputs in context by showing not only how much a feature influenced the prediction, but also what specific value it had. This addition significantly enhanced interpretability, allowing users to trace how real-world inputs—like a home’s square footage or number of rooms—translated into changes in estimated price.\n",
    "\n",
    "Together, these refinements enhanced the dashboard’s clarity, usability, and alignment with user expectations. The result is a tool that not only fosters trust in AI predictions but also promotes meaningful user engagement with model explanations in a high-stakes decision-making context like real estate.\n",
    "\n",
    "## Description of the Final Prototype with Visualizations\n",
    "\n",
    "The final prototype expands on the core structure of the initial implementation, offering a complete, polished dashboard that enables users to explore, compare, and contextualize AI predictions in an interactive and educational environment. Designed with feedback from multiple user testing sessions, the final version maintains the dual-method focus on SHAP and LIME while enhancing usability, interactivity, and clarity.\n",
    "\n",
    "![Dashboard Overview](Images/Homepage.png)\n",
    "\n",
    "Upon launching the dashboard, users are welcomed by a streamlined interface that begins with the selection of a random house from the dataset. This selection dynamically updates the dashboard, triggering the rendering of explanations tailored to the chosen property. An expandable panel provides the original, non-normalized feature values, anchoring abstract explanations in real-world data.\n",
    "\n",
    "![Random House Selection and Expendable Panel of Original Feautures](Images/Title.png)\n",
    "\n",
    "The explanation interface is organized into two symmetrical panels. On the left, the SHAP module includes a waterfall plot that visualizes how each feature pushes the prediction higher or lower for the selected sample. Below it, a summary plot presents global feature importance across the dataset, with color-coding (red for high values, blue for low) helping users intuitively grasp trends. Hoverable tooltips provide immediate, simple explanations for each plot element, aiding interpretation.\n",
    "\n",
    "![SHAP Waterfall and Summary Plots](Images/SHAP.png)\n",
    "\n",
    "On the right side, the LIME module delivers a local explanation for the same house using an HTML-rendered visualization. This shows how individual feature conditions contributed to the prediction, based on slight perturbations to the inputs. Tooltips again support user understanding by clarifying the method’s logic and the meaning of the visual outputs.\n",
    "\n",
    "![LIME Explanation Plots](Images/LIME.png)\n",
    "\n",
    "A central innovation is the feature comparison module. This component extracts the top five features highlighted by SHAP and LIME for the selected prediction, displays them in a structured table, and highlights any overlap. By explicitly drawing attention to agreement or disagreement, the dashboard fosters deeper user engagement with the reasoning processes behind AI predictions and encourages reflection on why models may disagree.\n",
    "\n",
    "![Top Feature Comparison Between SHAP and LIME](Images/Comparison.png)\n",
    "\n",
    "Another important feature added during development was a toggle to reveal the original value of each feature for the selected house. This contextual view allows users to see not just that a feature influenced a prediction, but how its specific value (e.g., “Living space: 140 m²”) contributed to the outcome. Labels were also revised to replace abstract numerical indices with more intuitive identifiers (e.g., “House #23”), reducing confusion and enhancing navigation.\n",
    "\n",
    "To further involve users, the final section of the dashboard includes a feedback module. Here, users can indicate which explanation they found easier to understand and more trustworthy. They are also invited to leave open comments, enabling the design team to gather continuous input for iterative refinement.\n",
    "\n",
    "![Feedback Module](Images/Feedback.png)\n",
    "\n",
    "Taken together, the final prototype successfully embodies the original design challenge: enabling users—especially those with a foundational understanding of data science—to critically assess and interpret AI-driven predictions for housing prices. The dashboard transforms abstract XAI theory into a usable, transparent, and reflective tool that supports trust and comprehension in high-stakes decision-making contexts.\n",
    "\n",
    "## Visualization of the Interaction of the User with the Concept in the Use-Context\n",
    "\n",
    "The interaction design was grounded in the design thinking framework, emphasizing empathy with users, iterative prototyping, and continuous feedback. The user journey reflects a real-world scenario in which a data science student is attempting to understand an AI model’s prediction for a specific house. Motivated by a desire to make an informed housing decision, the student selects a house, reviews its original features, and examines both SHAP and LIME explanations.\n",
    "\n",
    "They analyze how the features contributed to the predicted price, using the waterfall and summary plots for SHAP, and LIME’s localized feature impact visualization. Through the feature comparison table, the student observes where SHAP and LIME agree or differ and reflects on which explanation feels more trustworthy. If confusion arises, they consult integrated tooltips or the feature overview panel. After their exploration, they provide feedback, which contributes to refining the tool in future iterations.\n",
    "\n",
    "This use-context illustrates how the dashboard supports informed decision-making by making complex AI predictions more understandable and transparent. It bridges the gap between model complexity and user comprehension, particularly for first-time homebuyers with a technical background, offering a robust platform for interpretability in high-stakes scenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff8f274c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/pdf": "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",
      "text/plain": [
       "<Figure size 8400x3600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: false\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import FancyBboxPatch\n",
    "import numpy as np\n",
    "\n",
    "steps = [\n",
    "    (\"Empathize\", \"We conducted interviews with students\\nto understand their needs.\"),\n",
    "    (\"Define\", \"We focused on the disagreement problem\\ndescribed by Kaur et al. in 2020.\"),\n",
    "    (\"Ideate\", \"We brainstormed ideas and used the COCD matrix\\nto choose the most feasible and innovative features.\"),\n",
    "    (\"Prototype\", \"We built the tool using Python and Streamlit,\\nwith models from XGBoost and PyTorch.\"),\n",
    "    (\"Test\", \"We conducted qualitative testing with real users.\"),\n",
    "    (\"Iterate\", \"Based on their feedback, we simplified the LIME layout,\\nadded labels, and built original features.\")\n",
    "]\n",
    "\n",
    "# Reintroduce the colors dataset for clarity and ensure it's used\n",
    "colors = ['#5B9BD5', '#70AD47', '#FFC000', '#ED7D31', '#A93226', '#6C3483']\n",
    "\n",
    "# Set hexagon size so all sides are equal: width = sqrt(3) * height\n",
    "hex_height = 6.0\n",
    "hex_width = np.sqrt(3) * hex_height  # ≈10.392\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(28, 12))\n",
    "ax.axis('off')\n",
    "\n",
    "fig.suptitle(\"Design Thinking Process for XAI Dashboard\", fontsize=38, color='#222222', weight='bold', y=0.97)\n",
    "\n",
    "for i, (title, desc) in enumerate(steps):\n",
    "    y = 2.0 if i % 2 == 0 else 0\n",
    "    x = i * (hex_width * 0.95)\n",
    "\n",
    "    # Centered regular hexagon with equal sides\n",
    "    hexagon = [\n",
    "        (x + hex_width/2 * np.cos(theta), y + hex_height/2 * np.sin(theta))\n",
    "        for theta in np.linspace(0, 2 * np.pi, 7)\n",
    "    ]\n",
    "    hex_patch = plt.Polygon(hexagon, closed=True, facecolor=colors[i], edgecolor='none', alpha=0.92)\n",
    "    ax.add_patch(hex_patch)\n",
    "\n",
    "    ax.text(x, y, title, ha='center', va='center', fontsize=32, color='white', weight='bold')\n",
    "\n",
    "    if i % 2 == 0:\n",
    "        desc_y = y + hex_height / 1.7\n",
    "        va = 'bottom'\n",
    "    else:\n",
    "        desc_y = y - hex_height / 1.7\n",
    "        va = 'top'\n",
    "    ax.text(x, desc_y, desc, ha='center', va=va, fontsize=20, color=colors[i], wrap=True, linespacing=1.5)\n",
    "\n",
    "plt.xlim(-4, x + hex_width * 1.2)\n",
    "plt.ylim(-7, 7)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab8bc16",
   "metadata": {},
   "source": [
    "# Short description of design archive\n",
    "\n",
    "- *Method overview, references to the archive that contains materials used in user research (e.g. probe materials, interview guide, observation scheme), the notes you took throughout your design process and collected RAW data.*\n",
    "\n",
    "![Design Archive](Images/Design.png)\n",
    "\n",
    "The design archive serves as a comprehensive record of the development process behind the explainable AI dashboard prototype. It captures the progression from initial problem framing to ideation, user testing, and final implementation. At its core, the archive reflects a design thinking approach, evidenced by documented brainstorming sessions, early concept sketches, and prioritization of ideas using the COCD matrix method. These visual artifacts reveal how the team explored a wide solution space before converging on the most feasible and user-relevant features.\n",
    "\n",
    "Supporting this creative process, the archive includes detailed materials from the pilot testing phase with data science students, who represent the dashboard’s target audience. This includes raw transcripts from user testing sessions, capturing participants’ real-time reactions, questions, and feedback as they interacted with the prototype. In addition, the archive contains a structured user test results table summarizing each participant’s Likes, Criticisms, Questions, Ideas, and Comments. This table provides a clear overview of user sentiment and highlights actionable insights for further refinement.\n",
    "\n",
    "Screenshots of the prototype in use during testing are also included, illustrating how users engaged with the dashboard and where they encountered challenges or confusion. These qualitative data sources were critical in shaping the user experience, particularly around explanation clarity, interface language, and overall usability.\n",
    "\n",
    "The archive further contains both the prototype and final versions of the dashboard Python files, as well as the dataset used for model training and evaluation. These code and data artifacts document the technical evolution of the project, making it possible to trace how user feedback and design decisions were translated into concrete implementation changes.\n",
    "\n",
    "Additionally, the archive includes posters created for the pitch sessions, which visually summarize the project’s goals, design process, and key findings. These posters were used to communicate the concept and progress to docents and peers during formal presentations.\n",
    "\n",
    "Altogether, the archive illustrates a transparent and traceable design process grounded in iterative refinement, user feedback, and interdisciplinary collaboration. By including both raw user testing transcripts and a structured feedback table, it provides a robust foundation for replicability and continued improvement of explainable AI systems aimed at non-expert users."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c52955c",
   "metadata": {},
   "source": [
    "# References\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
